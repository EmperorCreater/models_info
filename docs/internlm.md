InternLM 是由上海人工智能实验室推出的一系列大型语言模型，它包括多个不同规模的模型，旨在提供强大的自然语言处理能力。以下是关于 InternLM 的一些关键信息：

1. **模型系列**：InternLM 系列模型包括 InternLM-7B 和 InternLM-20B 等不同参数规模的模型，其中 InternLM-7B 是一个70亿参数的轻量级模型，而 InternLM-20B 则拥有更大的参数规模。
2. **特点**：
   - **推理性能**：InternLM 在数学推理方面表现出色，精度超越了同量级模型如 Llama3 和 Gemma2-9B。
   - **超长上下文支持**：模型能够有效处理百万字的超长上下文，几乎完美地实现长文本中的信息检索，并在 LongBench 等长文本任务中表现领先。
   - **工具调用能力**：InternLM2.5 支持从上百个网页搜集有效信息进行分析推理，具有更强和更泛化的指令理解、工具筛选与结果反思能力。
3. **开源框架**：InternLM 提供了一个轻量级的预训练框架，支持在单 GPU 上进行微调，以及在数千个 GPU 的大型集群上进行预训练，并实现了卓越的性能优化。
4. **模型应用**：InternLM 模型已在多个平台上发布，包括 Transformers、ModelScope 和 OpenXLab，用户可以根据自己的需求下载相应的模型进行应用。
5. **技术报告**：InternLM 的技术报告已在 arXiv 上发布，提供了模型的详细技术细节和研究结果。
6. **社区和贡献**：InternLM 欢迎社区用户参与项目贡献，并提供了贡献指南，以促进项目的持续改进和发展。

InternLM 通过全面开源，为全球开发者提供了强大的技术基础和支持，推动了人工智能技术的共享和创新。随着技术的不断进步和应用场景的不断拓展，InternLM 将在未来发挥更加重要的作用。

[点击进入Github查看其中文文档。](https://github.com/InternLM/InternLM/blob/main/README_zh-CN.md)

